{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('Sonya.ai': conda)",
   "display_name": "Python 3.8.5 64-bit ('Sonya.ai': conda)",
   "metadata": {
    "interpreter": {
     "hash": "886eed32a51e62ce102904e8f9a10d2b0436e03dd17f1d54005ff0989d11a7c8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Keras \n",
    "### An API specification that's used for defining and training machine learning models\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Keras.Sequential  API - CNN example \n",
    "\n",
    "1.  tf.Keras.Sequential builds a tf.keras.Model object by stacking Keras layers\n",
    "2.  model.compile - creates a training loop \n",
    "3.  model.fit - executes the training loop \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist, cifar10\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "source": [
    "### Prepare data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Set: (60000, 28, 28)\nTest Set: (10000, 28, 28)\nInput shape: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "(train, train_labels), (test, test_labels) = fashion_mnist.load_data()\n",
    "# (train, train_labels), (test, test_labels) = cifar10.load_data()\n",
    "\n",
    "print(f\"Training Set: {train.shape}\")\n",
    "print(f\"Test Set: {test.shape}\")\n",
    "print(f\"Input shape: {train[0].shape}\")\n",
    "\n",
    "input_shape = test[0].shape\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Build CNN classification model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"Net\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nKS_CONV_1 (Conv2D)           (None, 24, 24, 32)        832       \n_________________________________________________________________\nKS_POOL_1 (MaxPooling2D)     (None, 12, 12, 32)        0         \n_________________________________________________________________\nKS_CONV_2 (Conv2D)           (None, 10, 10, 64)        18496     \n_________________________________________________________________\nKS_POOL_2 (MaxPooling2D)     (None, 5, 5, 64)          0         \n_________________________________________________________________\nKS_CONV_3 (Conv2D)           (None, 3, 3, 32)          18464     \n_________________________________________________________________\nKS_POOL_3 (MaxPooling2D)     (None, 1, 1, 32)          0         \n_________________________________________________________________\nKS_FLATTEN (Flatten)         (None, 32)                0         \n_________________________________________________________________\nKS_FC_1 (Dense)              (None, 1024)              33792     \n=================================================================\nTotal params: 71,584\nTrainable params: 71,584\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = 10\n",
    "# build a tf.keras.Model object by stacking Keras layers \n",
    "model = tf.keras.Sequential(name=\"Net\")\n",
    "\n",
    "# first layer, if no input layer is specified the ouputs (shapes) of the subsequent \n",
    "# layers is unknown and summary can not be generated. \n",
    "model.add(layers.Conv2D(32, (5,5), activation=tf.nn.relu, input_shape=(28,28,1), name=\"KS_CONV_1\")) \n",
    "model.add(layers.MaxPool2D((2,2), (2,2), name=\"KS_POOL_1\")) \n",
    "model.add(layers.Conv2D(64, (3,3), activation=tf.nn.relu, name=\"KS_CONV_2\")) \n",
    "model.add(layers.MaxPool2D((2,2), (2,2), name=\"KS_POOL_2\"))\n",
    "model.add(layers.Conv2D(32, (3,3), activation=tf.nn.relu, name=\"KS_CONV_3\"))\n",
    "model.add(layers.MaxPool2D((2,2), (2,2), name=\"KS_POOL_3\"))\n",
    "model.add(layers.Flatten(name=\"KS_FLATTEN\"))\n",
    "model.add(layers.Dense(1024, activation=tf.nn.relu, name=\"KS_FC_1\"))\n",
    "tf.keras.layers.Dropout(0.5, name=\"KS_DROPOUT\")\n",
    "tf.keras.layers.Dense(number_of_classes, name=\"KS_FC_OUTPUT\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Preprocess data, start training loop "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.3171 - accuracy: 0.1026\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.3031 - accuracy: 0.1044\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.3029 - accuracy: 0.1050\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.3022 - accuracy: 0.1068\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.3021 - accuracy: 0.1094\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.3018 - accuracy: 0.1064\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.3014 - accuracy: 0.1097\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 2.3010 - accuracy: 0.1095\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.3003 - accuracy: 0.1121\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 2.2997 - accuracy: 0.1126\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nPlease provide data which shares the same first dimension.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-b80e4c03bbb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# execute the training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Sonya.ai\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Sonya.ai\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1342\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m         \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m         data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1345\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Sonya.ai\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Sonya.ai\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[0;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "# Scale input in [-1, 1] range\n",
    "# preprocess using eager execution.\n",
    "train = train / 255. * 2 - 1\n",
    "test = test / 255. * 2 - 1\n",
    "train = tf.expand_dims(train, -1).numpy()\n",
    "test = tf.expand_dims(train, -1).numpy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "# optimizer = tf.keras.optimizers.SGD(1e-5)\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# create a training loop \n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# execute the training loop \n",
    "model.fit(train, train_labels, epochs=10)\n",
    "model.evaluate(test, test_labels)\n"
   ]
  },
  {
   "source": [
    "# Keras Functional API \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. The functional API allows you to build complex models\n",
    "2. Multi-input, multi-output models, easily sharing layers\n",
    "3. Residual connections \n",
    "4. In general define a model with arbitrary and complex topologies \n",
    "5. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "input_shape = (100, )\n",
    "\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "net = tf.keras.layers.Dense(units=64, activation=tf.nn.relu, name='FC1')(inputs)\n",
    "net = tf.keras.layers.Dense(units=64, activation=tf.nn.relu, name='FC2')(net)\n",
    "\n",
    "net = tf.keras.layers.Dense(units=1, name='G')(net)\n",
    "model= tf.keras.Model(inputs=inputs, outputs=net)\n",
    "\n",
    "model.summary()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 100)]             0         \n_________________________________________________________________\nFC1 (Dense)                  (None, 64)                6464      \n_________________________________________________________________\nFC2 (Dense)                  (None, 64)                4160      \n_________________________________________________________________\nG (Dense)                    (None, 1)                 65        \n=================================================================\nTotal params: 10,689\nTrainable params: 10,689\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# The subclassing method\n",
    "\n",
    "1. The Sequential and Functional APIs cover almost any possible scenario. \n",
    "2. Subclassing can be more flexible, but error-prone and harder to debug.\n",
    "3. recommended since it separates the layer definition from its usage, making it easy to make mistakes while refactoring the code.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_1 = layers.Dense(\n",
    "        units=64, activation=tf.nn.elu, name=\"fc1\")\n",
    "        self.dense_2 = layers.Dense(\n",
    "        units=64, activation=tf.nn.elu, name=\"fc2\")\n",
    "        self.output = layers.Dense(units=1, name=\"G\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Build the model in functional style here\n",
    "        # and return the output tensor\n",
    "        net = self.dense_1(inputs)\n",
    "        net = self.dense_2(net)\n",
    "        net = self.output(net)\n",
    "\n",
    "        return net        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}